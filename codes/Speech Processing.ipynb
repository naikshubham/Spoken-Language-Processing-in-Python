{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From AudioFile to AudioData\n",
    "- read the audio file using the AudioFile class. But the `recognize_google()` method requires an input of type `AudioData`.\n",
    "- To convert our AudioFile to AudioData, we'll use the Recognizer class's `method record()` along with a context manager. The `record()` method takes an AudioFile as input and converts it to AudioData, ready to be used with `recognize_google()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello I want to get some help setting up my time please\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Convert audio to AudioFile\n",
    "clean_support_call = sr.AudioFile('../data/clean-support-call.wav')\n",
    "\n",
    "# Convert AudioFile to AudioData\n",
    "with clean_support_call as source:\n",
    "    clean_support_call_audio = recognizer.record(source)\n",
    "\n",
    "# Transcribe AudioData to text\n",
    "text = recognizer.recognize_google(clean_support_call_audio,\n",
    "                                   language=\"en-US\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We've imported an audio file, converted it to the right data type and transcribed it using Google's free web API!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording the audio we need\n",
    "- Sometimes we may not want the entire audio file we're working with. The duration and offset parameters of the record() method can help with this.\n",
    "- After exploring our dataset, we find there's one file,which has 30-seconds of silence at the end and a support call file, 3-seconds of static at the front.\n",
    "- Setting duration and offset means the record() method will record up to duration audio starting at offset. They're both measured in seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's get the first 10-seconds of nothing_at_end_audio. To do this, we can set duration to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Odia call has 30 seconds of nothing at the end\n"
     ]
    }
   ],
   "source": [
    "# Convert AudioFile to AudioData\n",
    "nothing_at_end = sr.AudioFile('../data/30-seconds-of-nothing-16k.wav')\n",
    "\n",
    "with nothing_at_end as source:\n",
    "    nothing_at_end_audio = recognizer.record(source,\n",
    "                                             duration=10,\n",
    "                                             offset=None)\n",
    "\n",
    "# Transcribe AudioData to text\n",
    "text = recognizer.recognize_google(nothing_at_end_audio,\n",
    "                                   language=\"en-US\")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's remove the first 3-seconds of static of static_at_start by setting offset to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello I like to get some help with my device please I think it's I want I want to do back to you\n"
     ]
    }
   ],
   "source": [
    "# Convert AudioFile to AudioData\n",
    "static_at_start = sr.AudioFile('../data/static-out-of-warranty.wav')\n",
    "\n",
    "with static_at_start as source:\n",
    "    static_art_start_audio = recognizer.record(source,\n",
    "                                               duration=None,\n",
    "                                               offset=3)\n",
    "\n",
    "# Transcribe AudioData to text\n",
    "text = recognizer.recognize_google(static_art_start_audio,\n",
    "                                   language=\"en-US\")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Speech recognition can be resource intensive, so in practice, we'll want to explore your audio files to make sure we're not wasting any compute power trying to transcribe static or silence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
