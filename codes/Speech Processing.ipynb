{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From AudioFile to AudioData\n",
    "- read the audio file using the AudioFile class. But the `recognize_google()` method requires an input of type `AudioData`.\n",
    "- To convert our AudioFile to AudioData, we'll use the Recognizer class's `method record()` along with a context manager. The `record()` method takes an AudioFile as input and converts it to AudioData, ready to be used with `recognize_google()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello I want to get some help setting up my time please\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Convert audio to AudioFile\n",
    "clean_support_call = sr.AudioFile('../data/clean-support-call.wav')\n",
    "\n",
    "# Convert AudioFile to AudioData\n",
    "with clean_support_call as source:\n",
    "    clean_support_call_audio = recognizer.record(source)\n",
    "\n",
    "# Transcribe AudioData to text\n",
    "text = recognizer.recognize_google(clean_support_call_audio,\n",
    "                                   language=\"en-US\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We've imported an audio file, converted it to the right data type and transcribed it using Google's free web API!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recording the audio we need\n",
    "- Sometimes we may not want the entire audio file we're working with. The duration and offset parameters of the record() method can help with this.\n",
    "- After exploring our dataset, we find there's one file,which has 30-seconds of silence at the end and a support call file, 3-seconds of static at the front.\n",
    "- Setting duration and offset means the record() method will record up to duration audio starting at offset. They're both measured in seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's get the first 10-seconds of nothing_at_end_audio. To do this, we can set duration to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this Odia call has 30 seconds of nothing at the end\n"
     ]
    }
   ],
   "source": [
    "# Convert AudioFile to AudioData\n",
    "nothing_at_end = sr.AudioFile('../data/30-seconds-of-nothing-16k.wav')\n",
    "\n",
    "with nothing_at_end as source:\n",
    "    nothing_at_end_audio = recognizer.record(source,\n",
    "                                             duration=10,\n",
    "                                             offset=None)\n",
    "\n",
    "# Transcribe AudioData to text\n",
    "text = recognizer.recognize_google(nothing_at_end_audio,\n",
    "                                   language=\"en-US\")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's remove the first 3-seconds of static of static_at_start by setting offset to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello I like to get some help with my device please I think it's a warranty I want to do back to you\n"
     ]
    }
   ],
   "source": [
    "# Convert AudioFile to AudioData\n",
    "static_at_start = sr.AudioFile('../data/static-out-of-warranty.wav')\n",
    "\n",
    "with static_at_start as source:\n",
    "    static_art_start_audio = recognizer.record(source,\n",
    "                                               duration=None,\n",
    "                                               offset=3)\n",
    "\n",
    "# Transcribe AudioData to text\n",
    "text = recognizer.recognize_google(static_art_start_audio,\n",
    "                                   language=\"en-US\")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Speech recognition can be resource intensive, so in practice, we'll want to explore your audio files to make sure we're not wasting any compute power trying to transcribe static or silence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different kinds of audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pass the Japanese version of good morning (japanese_audio) to recognize_google() using \"en-US\" as the language.\n",
    "- Pass the same Japanese audio (japanese_audio) using \"ja\" as the language parameter.\n",
    "- What about about non-speech audio? Pass leopard_audio to recognize_google() with show_all as True.\n",
    "- What if our speech files have non-audible human sounds? Pass charlie_audio to recognize_google() to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mass\n"
     ]
    }
   ],
   "source": [
    "# Convert AudioFile to AudioData\n",
    "japanese_audio = sr.AudioFile('../data/good-morning-japanense.wav')\n",
    "\n",
    "with japanese_audio as source:\n",
    "    japanese_audio = recognizer.record(source)\n",
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Pass the Japanese audio to recognize_google\n",
    "text = recognizer.recognize_google(japanese_audio, language='en-US')\n",
    "\n",
    "# Print the text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "おはようございます\n"
     ]
    }
   ],
   "source": [
    "# Convert AudioFile to AudioData\n",
    "japanese_audio = sr.AudioFile('../data/good-morning-japanense.wav')\n",
    "\n",
    "with japanese_audio as source:\n",
    "    japanese_audio = recognizer.record(source)\n",
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Pass the Japanese audio to recognize_google\n",
    "text = recognizer.recognize_google(japanese_audio, language='ja')\n",
    "\n",
    "# Print the text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Convert AudioFile to AudioData\n",
    "leopard_audio = sr.AudioFile('../data/leopard.wav')\n",
    "\n",
    "with leopard_audio as source:\n",
    "    leopard_audio = recognizer.record(source)\n",
    "\n",
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Pass the leopard roar audio to recognize_google\n",
    "text = recognizer.recognize_google(leopard_audio, \n",
    "                                   language=\"en-US\", \n",
    "                                   show_all=True)\n",
    "\n",
    "# Print the text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choli\n"
     ]
    }
   ],
   "source": [
    "# Convert AudioFile to AudioData\n",
    "charlie_audio = sr.AudioFile('../data/charlie-bit-me-5.wav')\n",
    "\n",
    "with charlie_audio as source:\n",
    "    charlie_audio = recognizer.record(source)\n",
    "\n",
    "\n",
    "# Create a recognizer class\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Pass charlie_audio to recognize_google\n",
    "text = recognizer.recognize_google(charlie_audio, \n",
    "                                   language=\"en-US\")\n",
    "\n",
    "# Print the text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with noisy audio\n",
    "- start by transcribing a clean speech sample to text and then see what happens when we add some background noise.\n",
    "- To try and negate the background noise, we'll take advantage of Recognizer's adjust_for_ambient_noise() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello I want to get some help setting up my time please\n"
     ]
    }
   ],
   "source": [
    "# Read in clean_support_call as the source and call recognize_google() on the file.\n",
    "clean_support_call = sr.AudioFile('../data/clean-support-call.wav')\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Record the audio from the clean support call\n",
    "with clean_support_call as source:\n",
    "  clean_support_call_audio = recognizer.record(source)\n",
    "\n",
    "# Transcribe the speech from the clean support call\n",
    "text = recognizer.recognize_google(clean_support_call_audio,\n",
    "\t\t\t\t\t   language=\"en-US\")\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alternative': [{'transcript': 'my family', 'confidence': 0.69139749}, {'transcript': 'family'}, {'transcript': 'about family'}, {'transcript': 'MP3'}, {'transcript': 'Koi family'}], 'final': True}\n"
     ]
    }
   ],
   "source": [
    "# Let's do the same as before but with a noisy audio file and show_all parameter as True.\n",
    "noisy_support_call = sr.AudioFile('../data/2-noisy-support-call.wav')\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Record the audio from the noisy support call\n",
    "with noisy_support_call as source:\n",
    "  noisy_support_call_audio = recognizer.record(source)\n",
    "\n",
    "# Transcribe the speech from the noisy support call\n",
    "text = recognizer.recognize_google(noisy_support_call_audio,\n",
    "                         language=\"en-US\",\n",
    "                         show_all=True)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Set the duration parameter of adjust_for_ambient_noise() to 1 (second) so recognizer adjusts for background noise.\n",
    "noisy_support_call = sr.AudioFile('../data/2-noisy-support-call.wav')\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Record the audio from the noisy support call\n",
    "with noisy_support_call as source:\n",
    "    # Adjust the recognizer energy threshold for ambient noise\n",
    "    recognizer.adjust_for_ambient_noise(source, duration=1)\n",
    "    noisy_support_call_audio = recognizer.record(noisy_support_call)\n",
    " \n",
    "#  Transcribe the speech from the noisy support call\n",
    "text = recognizer.recognize_google(noisy_support_call_audio,\n",
    "                                   language=\"en-US\",\n",
    "                                   show_all=True)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# A duration of 1 was too long and it cut off some of the audio. Try setting duration to 0.5.\n",
    "noisy_support_call = sr.AudioFile('../data/2-noisy-support-call.wav')\n",
    "\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Record the audio from the noisy support call\n",
    "with noisy_support_call as source:\n",
    "\t# Adjust the recognizer energy threshold for ambient noise\n",
    "    recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "    noisy_support_call_audio = recognizer.record(noisy_support_call)\n",
    " \n",
    "# Transcribe the speech from the noisy support call\n",
    "text = recognizer.recognize_google(noisy_support_call_audio,\n",
    "                                   language=\"en-US\",\n",
    "                                   show_all=True)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import an audio file with PyDub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham\\Anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pydub.audio_segment.AudioSegment'>\n"
     ]
    }
   ],
   "source": [
    "# Import AudioSegment from Pydub\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Create an AudioSegment instance\n",
    "wav_file = AudioSegment.from_file(file='../data/wav_file.wav', \n",
    "                                  format=\"wav\")\n",
    "\n",
    "# Check the type\n",
    "print(type(wav_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play an audio file with PyDub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham\\Anaconda3\\lib\\site-packages\\pydub\\utils.py:184: RuntimeWarning: Couldn't find ffplay or avplay - defaulting to ffplay, but may not work\n",
      "  warn(\"Couldn't find ffplay or avplay - defaulting to ffplay, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import AudioSegment and play\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "# Create an AudioSegment instance\n",
    "wav_file = AudioSegment.from_file(file=\"../data/wav_file.wav\", \n",
    "                                  format=\"wav\")\n",
    "\n",
    "# Play the audio file\n",
    "play(wav_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio parameters with PyDub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n",
      "2\n",
      "8484\n",
      "3284\n"
     ]
    }
   ],
   "source": [
    "# Import audio file\n",
    "wav_file = AudioSegment.from_file(file=\"../data/wav_file.wav\")\n",
    "\n",
    "# Find the frame rate\n",
    "print(wav_file.frame_rate)\n",
    "\n",
    "# Find the number of channels\n",
    "print(wav_file.channels)\n",
    "\n",
    "# Find the max amplitude\n",
    "print(wav_file.max)\n",
    "\n",
    "# Find the length\n",
    "print(len(wav_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting audio parameters\n",
    "- During our exploratory data analysis, we may find some of the parameters of our audio files differ or are incompatible with speech recognition APIs.\n",
    "- PyDub has built-in functionality which allows us to change various attributes.\n",
    "- For example, we can set the frame rate of our audio file calling `set_frame_rate()` on our AudioSegment instance and passing it an integer of the desired frame rate measured in Hertz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "# Import audio file\n",
    "wav_file = AudioSegment.from_file(file=\"../data/wav_file.wav\")\n",
    "\n",
    "# Create a new wav file with adjusted frame rate\n",
    "wav_file_16k = wav_file.set_frame_rate(16000)\n",
    "\n",
    "# Check the frame rate of the new wav file\n",
    "print(wav_file_16k.frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Import audio file\n",
    "wav_file = AudioSegment.from_file(file=\"../data/wav_file.wav\")\n",
    "\n",
    "# Set number of channels to 1\n",
    "wav_file_1_ch = wav_file.set_channels(1)\n",
    "\n",
    "# Check the number of channels\n",
    "print(wav_file_1_ch.channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old sample width: 2\n",
      "New sample width: 1\n"
     ]
    }
   ],
   "source": [
    "# Import audio file\n",
    "wav_file = AudioSegment.from_file(file=\"../data/wav_file.wav\")\n",
    "\n",
    "# Print sample_width\n",
    "print(f\"Old sample width: {wav_file.sample_width}\")\n",
    "\n",
    "# Set sample_width to 1\n",
    "wav_file_sw_1 = wav_file.set_sample_width(1)\n",
    "\n",
    "# Check new sample_width\n",
    "print(f\"New sample width: {wav_file_sw_1.sample_width}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyDub : make an AudioSegment quieter or louder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Import audio file\n",
    "volume_adjusted = AudioSegment.from_file('../data/volume_adjusted.wav')\n",
    "\n",
    "# Lower the volume by 60 dB\n",
    "quiet_volume_adjusted = volume_adjusted - 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import audio file\n",
    "volume_adjusted = AudioSegment.from_file('../data/volume_adjusted.wav')\n",
    "\n",
    "# Increase the volume by 15 dB\n",
    "louder_volume_adjusted = volume_adjusted + 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing an audio file with PyDub\n",
    "- Sometimes we'll have audio files where the speech is loud in some portions and quiet in others. Having this variance in volume can hinder transcription.\n",
    "- Luckily, PyDub's effects module has a function called `normalize()` which finds the maximum volume of an AudioSegment, then adjusts the rest of the AudioSegment to be in proportion. This means the quiet parts will get a volume boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AudioSegment and normalize\n",
    "from pydub import AudioSegment\n",
    "from pydub.effects import normalize\n",
    "\n",
    "# Import target audio file\n",
    "loud_then_quiet = AudioSegment.from_file('../data/volume_adjusted.wav')\n",
    "\n",
    "# Normalize target audio file\n",
    "normalized_loud_then_quiet = normalize(loud_then_quiet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chopping and changing audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Import part 1 and part 2 audio files\n",
    "part_1 = AudioSegment.from_file('../data/slicing_part_1.wav')\n",
    "part_2 = AudioSegment.from_file('../data/slicing_part_2.wav')\n",
    "\n",
    "# Remove the first four seconds of part 1\n",
    "part_1_removed = part_1[4000:]\n",
    "\n",
    "# Add the remainder of part 1 and part 2 together\n",
    "part_3 = part_1_removed + part_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting stereo audio to mono with PyDub\n",
    "- If we're trying to transcribe phone calls, there's a chance they've been recorded in stereo format, with one speaker on each channel.\n",
    "- As we've seen, it's hard to transcribe an audio file with more than one speaker. One solution is to split the audio file with multiple speakers into single files with individual speakers.\n",
    "- PyDub's split_to_mono() function can help with this. When called on an AudioSegment recorded in stereo, it returns a list of two separate AudioSegment's in mono format, one for each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stereo number channels: 2\n",
      "Split number channels: 1, 1\n"
     ]
    }
   ],
   "source": [
    "# Import AudioSegment\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Import stereo audio file and check channels\n",
    "stereo_phone_call = AudioSegment.from_file('../data/stereo_call.wav')\n",
    "print(f\"Stereo number channels: {stereo_phone_call.channels}\")\n",
    "\n",
    "# Split stereo phone call and check channels\n",
    "channels = stereo_phone_call.split_to_mono()\n",
    "print(f\"Split number channels: {channels[0].channels}, {channels[1].channels}\")\n",
    "\n",
    "# Save new channels separately\n",
    "phone_call_channel_1 = channels[0]\n",
    "phone_call_channel_2 = channels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting and reformatting audio files\n",
    "- If we've made some changes to our audio files, or if they've got the wrong file extension, we can use PyDub to export and save them as new audio files.\n",
    "- We can do this by using the `.export()` function on any instance of an AudioSegment we've created. The export() function takes two parameters, out_f, or the destination file path of our audio file and format, the format we'd like our new audio file to be. Both of these are strings. format is \"mp3\" by default so be sure to change it if we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='mp3_file.wav'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydub\n",
    "from pydub import AudioSegment\n",
    "AudioSegment.ffmpeg = \"ffmpeg.exe\"\n",
    "AudioSegment.ffprobe = \"ffprobe.exe\"\n",
    "# Import the .mp3 file\n",
    "mp3_file = AudioSegment.from_file('mp3_file_.mp3')\n",
    "\n",
    "# Export the .mp3 file as wav\n",
    "mp3_file.export(out_f=\"mp3_file.wav\",\n",
    "                format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding PyDub stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: 2\n",
      "Sample width: 2\n",
      "Frame rate (sample rate): 48000\n",
      "Frame width: 4\n",
      "Length (ms): 3519\n"
     ]
    }
   ],
   "source": [
    "def show_pydub_stats(filename):\n",
    "    \"\"\"Returns different audio attributes related to an audio file.\"\"\"\n",
    "    # Create AudioSegment instance\n",
    "    audio_segment = AudioSegment.from_file(filename)\n",
    "\n",
    "    # Print audio attributes and return AudioSegment instance\n",
    "    print(f\"Channels: {audio_segment.channels}\")\n",
    "    print(f\"Sample width: {audio_segment.sample_width}\")\n",
    "    print(f\"Frame rate (sample rate): {audio_segment.frame_rate}\")\n",
    "    print(f\"Frame width: {audio_segment.frame_width}\")\n",
    "    print(f\"Length (ms): {len(audio_segment)}\")\n",
    "    return audio_segment\n",
    "\n",
    "# Try the function\n",
    "call_1_audio_segment = show_pydub_stats('mp3_file.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
